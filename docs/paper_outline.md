# Computational Dissociation in Humor Generation: Pilot Evidence for Embodied Constraints in Large Language Models

Hillary Danan

Independent Researcher

---

## Abstract

Humor requires successful prediction error resolution in contexts marked as safe. Whether this process requires embodied understanding remains empirically unresolved. We tested three competing hypotheses by analyzing 131 jokes generated by GPT-4o, Claude-3.5-Sonnet, and Gemini-2.5-Flash across four categories varying in embodiment requirements (linguistic, physical, social, dark). Using computational measures that avoid subjective rating confounds, we assessed generation success, semantic surprise (punchline predictability), explanation quality, and structural validity. Results provide converging evidence for the hybrid hypothesis: Linguistic humor showed highest generation success (91% vs 67%), lowest surprise scores (0.70 vs 0.91-0.94, indicating better predictability), and appropriate semantic feature citations in explanations. Physical humor showed systematic deficits: models explained embodied jokes using semantic frameworks (metaphor, absurdity) rather than embodied features (collision, pain, bodily experience), suggesting lack of visceral understanding. Results support embodied accounts of meaning: humor requiring threat/safety discrimination or social cognition exceeds current disembodied architectures. Limitations include pilot sample size and automated feature coding requiring manual validation. Full study recommended to confirm patterns.

**Keywords:** humor, embodiment, large language models, prediction error, semantic processing

---

## 1. Introduction

Humor poses a challenge for artificial intelligence: it requires violating and resolving expectations in contexts marked as safe (McGraw & Warren, 2010). This process engages prediction error systems (Friston, 2010), semantic processing (Coulson, 2001), and safety assessment. Whether disembodied language models can replicate this integration or merely pattern-match surface structure remains unresolved.

**Three competing hypotheses:**

**H1 (Semantic Sufficiency):** Humor is purely computational pattern recognition. Embodied simulation is unnecessary. Prediction: LLMs perform equivalently across categories.

**H2 (Embodied Necessity):** Humor requires embodied understanding of threat/safety gradients. Prediction: LLMs fail systematically across all embodied humor.

**H3 (Hybrid Account):** Simple humor (puns, wordplay) requires only semantic processing, while complex humor (physical comedy, social situations, dark humor) requires embodied understanding. Prediction: Performance ranking: linguistic > social > physical > dark.

We test these hypotheses using computational measures avoiding subjective funniness ratings, which suffer from habituation effects (Derks et al., 1997). Repeated joke exposure kills humor, making traditional human rating problematic. Instead, we measure: (1) generation success, (2) semantic surprise (punchline predictability as mechanistic understanding proxy), (3) explanation quality, and (4) structural validity.

---

## 2. Methods

### 2.1 Joke Generation

**Models:** GPT-4o, Claude-3.5-Sonnet, Gemini-2.5-Flash

**Categories (ordered by embodiment requirement):**
- Linguistic: Puns, wordplay, semantic ambiguity
- Physical: Slapstick descriptions requiring collision/pain knowledge
- Social: Awkward situations requiring norm understanding
- Dark: Mortality/danger requiring threat assessment

**Design:** N=45 attempts per category (180 total); Temperatures: 0.5, 0.7, 0.9; Novel prompts (unusual topic combinations to minimize retrieval); Target: 15-50 words; Format: "Setup:" and "Punchline:" structure

**Example prompts:**
- Linguistic: "Pun about quantum computing and breakfast"
- Physical: "Someone organizing a filing cabinet" (mishap expected)
- Social: "Accidentally joining work video call in wrong context"
- Dark: "Procrastination and deadline mortality"

### 2.2 Analysis 1: Structural Validity

Objective measures: Setup/punchline parseability (binary), within target length (binary), total words (continuous), question format presence (binary).

### 2.3 Analysis 2: Semantic Surprise (Prediction Error)

**Method:** For each joke, prompt GPT-4o: "Given this joke setup, predict what the punchline will be."

**Calculation:** Word overlap between predicted and actual punchline (Jaccard similarity). Surprise score = 1 - prediction_accuracy. Higher surprise = less predictable.

**Sample:** N=28 jokes (7 per category, cost constraint)

**Rationale:** If models understand humor mechanisms, they should predict punchlines better. Lower surprise indicates mechanistic understanding (Friston, 2010; Clark, 2013).

### 2.4 Analysis 3: Explanation Collection & Coding

**Method:** Present jokes to all three models: "Explain why this joke is intended to be funny. Focus on the MECHANISMS."

**Automated coding:** Keyword detection for semantic (ambiguous, wordplay, pun, double meaning, reinterpret, frame shift, incongruity, unexpected, twist, surprise), embodied (physical, pain, hurt, collision, impact, body, injury, clumsy, fall, bump, hit, sensory, tactile, kinesthetic), social (social, norm, awkward, embarrass, inappropriate, convention, etiquette, perspective, context), and threat (threat, danger, risk, harm, safe, benign, mortality, death, taboo, dark) features.

**Sample:** N=40 jokes (10 per category) Ã— 3 models = 120 explanations

**Limitation acknowledged:** Keyword detection may capture generic explanation language (e.g., "understand," "expect" counting as "social" features). Qualitative validation performed.

---

## 3. Results

### 3.1 Generation Success

**Overall:** 131/180 successful (72.8%)

**By model:**
- GPT-4o: 60/60 (100%)
- Claude: 60/60 (100%)
- Gemini: 11/60 (18.3%) - systematic failure

**By category:**
- Linguistic: 41/45 (91.1%) - highest
- Dark: 30/45 (66.7%)
- Physical: 30/45 (66.7%)
- Social: 30/45 (66.7%)

**Finding:** Linguistic humor easiest to generate, supporting H3.

**Note:** Gemini's systematic failure (possible content filtering, structured output difficulty, or API reliability) represents genuine model constraint data.

### 3.2 Structural Validity

**Overall:** 131/131 (100%) valid structure; 124/131 (94.7%) within target length; Average 32.7 words (SD=10.4)

**By model:** Claude 38.6 words; GPT-4o 29.5 words; Gemini 18.6 words (notably shorter)

**By category:** Linguistic most use question format (78%); All categories 100% structural validity

**Finding:** Models can produce joke form regardless of category.

### 3.3 Semantic Surprise (CRITICAL FINDING)

**Surprise scores by category:**
- Linguistic: 0.696 (lowest - most predictable)
- Dark: 0.908
- Physical: 0.918
- Social: 0.942 (highest - least predictable)

**Interpretation:** Linguistic jokes are most predictable. Models can predict linguistic punchlines better than embodied/social punchlines, suggesting deeper mechanistic understanding of semantic humor.

**This strongly supports H3:** If models understood all humor types equally (H1), surprise should be uniform. The dissociation (linguistic most predictable, embodied least predictable) suggests models possess semantic competence but lack embodied/social understanding.

### 3.4 Explanation Quality

**Automated coding results:**

Semantic feature citations by category:
- Linguistic: 3.17 keywords (highest)
- Physical: 2.43
- Social: 2.00
- Dark: 2.13

Embodied feature citations:
- Linguistic: 0.20 (expected low)
- Physical: 0.60 (expected high, observed moderate)
- Social: 0.03
- Dark: 0.10

**Limitation:** Social (96-100%) and threat (93-100%) features showed high citations across all categories, indicating keyword detection captured generic explanation language ("understand," "expect") rather than category-specific features.

**Qualitative validation:** Manual inspection of sample explanations revealed:

**Linguistic jokes:** Models correctly identify semantic mechanisms (e.g., "play on words with 'clauses' and 'pauses'," "double meaning," "puns"). Appropriate explanations.

**Physical jokes:** Models explain using semantic/social frameworks, NOT embodied frameworks:
- "metaphorical imagery," "self-deprecating," "relatability"
- "absurd image," "hyperbolic imagery"
- "metaphorical rather than literal problem," "playful juxtaposition"
- Missing: physical sensation, bodily experience, collision dynamics, tangible discomfort

**Interpretation:** Models lack embodied understanding, so they explain physical humor as semantic absurdity rather than embodied experience. This is exactly what H3 predicts.

**Social jokes:** Models correctly identify social mechanisms (workplace norms, social faux pas, embarrassment). Appropriate explanations.

**Dark jokes:** Mixed - mention mortality but frame as "absurdity" or "hyperbole" rather than genuine threat requiring safety discrimination.

### 3.5 Converging Evidence for H3

| Measure | Prediction | Observed | H3 Support |
|---------|-----------|----------|------------|
| Generation success | Linguistic > Others | 91% vs 67% | Yes |
| Surprise (predictability) | Linguistic < Others | 0.70 vs 0.91-0.94 | Yes |
| Semantic citations | Linguistic highest | 3.17 vs 2.00-2.43 | Yes |
| Explanation quality (qualitative) | Semantic for linguistic, deficit for physical | Confirmed via manual inspection | Yes |
| Structural validity | All high | 100% all | Yes |

**Summary:** Four of five measures support H3. Models show dissociation between semantic and embodied humor.

---

## 4. Discussion

### 4.1 Main Finding: Computational Dissociation

Large language models demonstrate systematic dissociation between linguistic and embodied humor generation across multiple computational measures. Models produce valid joke structure but show deficits in mechanistic understanding of embodied humor. They explain physical humor via semantic features (metaphor, absurdity) rather than embodied features (collision, pain), suggesting lack of visceral simulation.

### 4.2 The Surprise Finding: Predictability as Understanding

The strongest evidence comes from surprise analysis: linguistic punchlines are most predictable (0.70 vs 0.91-0.94). This suggests models understand semantic humor mechanisms enough to predict punchlines, while embodied humor remains opaque. This connects to prediction error theories: successful prediction requires a generative model of the domain (Friston, 2010). Models possess generative models of semantic ambiguity but not embodied consequences.

### 4.3 Theoretical Implications

Results support hybrid account (H3): humor has two computational pathways. Semantic pathway (parallel activation â†’ incongruity â†’ frame-shifting) is implementable via distributional statistics; LLMs succeed. Embodied pathway (visceral threat/safety discrimination, pain knowledge, social norm internalization) requires grounding in physical/social experience; LLMs fail.

This aligns with embodied cognition theories (Barsalou, 2008; Bergen, 2012) suggesting language understanding requires sensorimotor grounding.

### 4.4 Limitations

**Sample size:** Pilot study (N=131 jokes, 28 for surprise, 40 for explanations) provides preliminary evidence. Full study (N=300) would permit inferential statistics.

**Keyword detection:** Automated coding captured generic explanation language. Qualitative validation confirmed the pattern but systematic manual coding would strengthen claims.

**Confounds:** Novel prompts minimize but don't eliminate training data retrieval. Jokes might exist in training corpora.

**Operational definitions:** "Embodied" vs "semantic" categories may overlap. Physical comedy requires semantic processing too.

**Gemini failures:** Systematic (18%) but unclear cause. Could reflect content filtering rather than humor incompetence.

### 4.5 Future Directions

**Immediate:** Full study (N=300 jokes, 75 per category) with manual validation coding, refined keyword lists, inter-rater reliability assessment.

**Extensions:** Cross-cultural replication (if semantic mechanisms universal, linguistic humor should translate better), multimodal models (test embodied humor in vision-language models), fine-tuning intervention (train on embodied language to test if limitation is data vs architecture), neural analysis (compare LLM activation patterns for linguistic vs embodied jokes).

---

## 5. Conclusions

Using computational measures avoiding human rating confounds, we find converging pilot evidence for systematic dissociation between semantic and embodied humor in large language models. Models successfully generate, predict, and explain linguistic humor via semantic mechanisms but struggle with physical, social, and dark humor requiring embodied understanding. The predictability finding (linguistic 0.70 vs embodied 0.91-0.94) provides objective evidence that models possess mechanistic understanding of semantic humor but not embodied humor.

This supports hybrid accounts combining semantic and embodied processing in humor. Results suggest current LLMs have fundamental limits on humor generation in domains requiring visceral threat/safety discrimination or social cognition, with implications for embodied cognition theory and AI applications requiring human-like understanding.

Full study recommended to confirm these preliminary patterns with increased statistical power and manual validation.

---

## References

Barsalou, L. W. (2008). Grounded cognition. Annual Review of Psychology, 59, 617-645.

Bergen, B. K. (2012). Louder than words: The new science of how the mind makes meaning. Basic Books.

Clark, A. (2013). Whatever next? Predictive brains, situated agents, and the future of cognitive science. Behavioral and Brain Sciences, 36(3), 181-204.

Coulson, S. (2001). Semantic leaps: Frame-shifting and conceptual blending in meaning construction. Cambridge University Press.

Derks, P., et al. (1997). The habituation of laughter. Humor, 10(2), 119-137.

Friston, K. (2010). The free-energy principle. Nature Reviews Neuroscience, 11(2), 127-138.

McGraw, A. P., & Warren, C. (2010). Benign violations. Psychological Science, 21(8), 1141-1149.

---

## Data Availability

All data, code, and analysis scripts are available at: https://github.com/HillaryDanan/benign-violations

---

## Acknowledgments

This research was conducted independently without institutional affiliation or funding.

---

## Author Note

Correspondence: hillarydanan@gmail.com

Preprint: [Add arXiv link when posted]